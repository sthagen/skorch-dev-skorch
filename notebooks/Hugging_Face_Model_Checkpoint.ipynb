{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating checkpoints on the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short notebook explains how you can create a model checkpoint on [Hugging Face Hub](https://huggingface.co/docs/hub/repositories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import TrainEndCheckpoint\n",
    "from skorch.hf import HfHubStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository, create_repo, HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not installed already, please install the [Hugging Face Hub](https://huggingface.co/docs/huggingface_hub/index) library:\n",
    "\n",
    "`$ python -m pip install huggingface_hub`\n",
    "\n",
    "Also, you need `skorch>=0.12` or installed from the master branch on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\"><td>\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/Hugging_Face_Checkpoint.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
    "</td><td>\n",
    "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/Hugging_Face_Checkpoint.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! [ ! -z \"$COLAB_GPU\" ] && pip install torch \"skorch>=0.12\" huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the token as an environment variable called HF_TOKEN, e.g. `HF_TOKEN=hf_...`\n",
    "# the token can be found at: https://huggingface.co/settings/tokens\n",
    "TOKEN = os.environ['HF_TOKEN']\n",
    "# choose name for the whole model and for the model weights\n",
    "# typically, you only need one of the two, we use both for demonstration purposes\n",
    "MODEL_NAME = 'skorch-model.pkl'\n",
    "WEIGHTS_NAME = 'weights.pt'\n",
    "# choose a repo name within your user account or organization\n",
    "REPO_NAME = 'BenjaminB/test-skorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a toy dataset for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(10000, 20, n_informative=10, random_state=0)\n",
    "X, y = X.astype(np.float32), y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=30,\n",
    "            nonlin=nn.ReLU(),\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_units, num_units)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = self.softmax(self.output(X))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a repository on Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the repo doesn't exist yet, create a new one using this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/BenjaminB/test-skorch'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skorch_repo = create_repo(\n",
    "    REPO_NAME,\n",
    "    private=True,  # set to False if it should be public\n",
    "    token=TOKEN,\n",
    "    exist_ok=True,\n",
    ")\n",
    "skorch_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `HfHubStorage` instance to use with the `TrainEndCheckpoint` callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ingredient we need to save models on the hub is the `skorch.hf.HfHubStorage`. This object can be used instead of a filename when you use `skorch.callbacks.TrainEndCheckpoint` (or `skorch.callbacks.Checkpoint`, but more on that later). Therefore, you can continue to use your existing checkpoints, only that models are stored on Hugging Face Hub instead of locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we need to create a `HfApi` instance, which is used by the `HfHubStorage` to perform the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_api = HfApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create a `hub_pickle_storer`, which is used by the checkpoint callback to write the whole skorch model as a pickle file to the indicated repository. We indicate the file path, repository name, and the Hugging Face token. Optionally, we can also set `verbose=1` to print a message when a file has been uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_pickle_storer = HfHubStorage(\n",
    "    hf_api,\n",
    "    path_in_repo=MODEL_NAME,\n",
    "    repo_id=REPO_NAME,\n",
    "    token=TOKEN,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of writing the whole skorch model to the Hub, we can also decide to only write specific components, e.g. the `module`. This saves the `state_dict` of the module to the Hub using `torch.save` under the hood.\n",
    "\n",
    "Also, by default, the parameters are stored in an in-memory buffer. If you want to avoid that memory overhead, it is possible to save it on disk using the `local_storage` argument. Below, we choose to store the model weights in a file called `my-model-weights.pt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_params_storer = HfHubStorage(\n",
    "    hf_api,\n",
    "    path_in_repo=WEIGHTS_NAME,\n",
    "    repo_id=REPO_NAME,\n",
    "    token=TOKEN,\n",
    "    verbose=1,\n",
    "    local_storage='my-model-weights.pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other attributes (optimizer, criterion, training history) are not saved for this demo. That's why we set their values to `None` when initializing the `TrainEndCheckpoint` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = TrainEndCheckpoint(\n",
    "    f_pickle=hub_pickle_storer,\n",
    "    f_params=hub_params_storer,\n",
    "    f_optimizer=None,\n",
    "    f_criterion=None,\n",
    "    f_history=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's create our net and fit it with the data. The checkpoint callback will automatically store the parameters on the Hugging Face Hub at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    lr=0.1,\n",
    "    device='cpu',\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6627\u001b[0m       \u001b[32m0.7573\u001b[0m        \u001b[35m0.5772\u001b[0m  0.1184\n",
      "      2        \u001b[36m0.5550\u001b[0m       \u001b[32m0.8593\u001b[0m        \u001b[35m0.4154\u001b[0m  0.0889\n",
      "      3        \u001b[36m0.4622\u001b[0m       \u001b[32m0.8973\u001b[0m        \u001b[35m0.3253\u001b[0m  0.1337\n",
      "      4        \u001b[36m0.4119\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m0.2840\u001b[0m  0.1137\n",
      "      5        \u001b[36m0.3739\u001b[0m       \u001b[32m0.9113\u001b[0m        \u001b[35m0.2569\u001b[0m  0.0892\n",
      "      6        \u001b[36m0.3489\u001b[0m       \u001b[32m0.9213\u001b[0m        \u001b[35m0.2368\u001b[0m  0.0978\n",
      "      7        \u001b[36m0.3331\u001b[0m       \u001b[32m0.9240\u001b[0m        \u001b[35m0.2328\u001b[0m  0.1332\n",
      "      8        \u001b[36m0.3115\u001b[0m       \u001b[32m0.9287\u001b[0m        \u001b[35m0.2187\u001b[0m  0.1163\n",
      "      9        0.3117       \u001b[32m0.9300\u001b[0m        \u001b[35m0.2087\u001b[0m  0.1244\n",
      "     10        \u001b[36m0.2983\u001b[0m       \u001b[32m0.9320\u001b[0m        0.2102  0.1537\n",
      "Uploaded file to https://huggingface.co/BenjaminB/test-skorch/blob/main/weights.pt\n",
      "Uploaded file to https://huggingface.co/BenjaminB/test-skorch/blob/main/skorch-model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (nonlin): ReLU()\n",
       "    (dense0): Linear(in_features=20, out_features=30, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (output): Linear(in_features=30, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, both the weights of the PyTorch module and the whole skorch model were saved on Hub. Visit the printed URLs to see them on the Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, think about adding a [Model Card](https://huggingface.co/docs/hub/models-cards) to your repository to provide further information about the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Info: Using the HfHubStorage with Checkpoint:</b><br>\n",
    "\n",
    "\n",
    "Right now, we use `TrainEndCheckpoint`, which uploads the model only once, at the end of training. Instead, we could use `Checkpoint`, which uploads the model each time that the monitored metric improves. You should note, however, that at the moment, the upload is _synchronous_, i.e. we wait for the upload to finish. So if uploading the model takes a long time compared to training the model, your training process could be slowed down considerably, depending on how often the model improves.\n",
    "\n",
    "If you still decide to use `Checkpoint`, you might want to keep a version of each upload file, instead of the latest one overwriting the previous one. This is possible by choosing a templated model name, e.g. `'skorch-model-{}.pkl'`. This way, the first upload will create the file `'skorch-model-0.pkl'`, the second one creates the file `'skorch-model-1.pkl'`, etc.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the whole model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skorch model is just a normal pickle file and can be loaded like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/BenjaminB/test-skorch/blob/main/skorch-model.pkl'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_pickle_storer.latest_url_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379867c1205f405e8b082753ceb86fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/43.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = hf_hub_download(REPO_NAME, MODEL_NAME, use_auth_token=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    net_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9334"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, net_loaded.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model weights are stored as a PyTorch `state_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/BenjaminB/test-skorch/blob/main/weights.pt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_params_storer.latest_url_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e49a51cc3a4444598e9d730667e5697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = hf_hub_download(REPO_NAME, WEIGHTS_NAME, use_auth_token=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    weights_loaded = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name 'dense0.weight' and shape torch.Size([30, 20])\n",
      "Parameter name 'dense0.bias' and shape torch.Size([30])\n",
      "Parameter name 'dense1.weight' and shape torch.Size([30, 30])\n",
      "Parameter name 'dense1.bias' and shape torch.Size([30])\n",
      "Parameter name 'output.weight' and shape torch.Size([2, 30])\n",
      "Parameter name 'output.bias' and shape torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for key, val in weights_loaded.items():\n",
    "    print(f\"Parameter name '{key}' and shape {val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, when you store the whole skorch model, you don't need to store the weights separately, as they are already part of the whole model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name 'dense0.weight' and shape torch.Size([30, 20])\n",
      "Parameter name 'dense0.bias' and shape torch.Size([30])\n",
      "Parameter name 'dense1.weight' and shape torch.Size([30, 30])\n",
      "Parameter name 'dense1.bias' and shape torch.Size([30])\n",
      "Parameter name 'output.weight' and shape torch.Size([2, 30])\n",
      "Parameter name 'output.bias' and shape torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for key, val in net_loaded.module_.state_dict().items():\n",
    "    print(f\"Parameter name '{key}' and shape {val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there can be situations where you don't need the whole skorch model, in which case you can only store the model weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
